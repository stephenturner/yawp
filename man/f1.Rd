% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/stats.R
\name{f1}
\alias{f1}
\title{Calculate F1 score}
\usage{
f1(.data, observed, truth, positive = "1", use_thresh = FALSE, thresh = 0.5)
}
\arguments{
\item{.data}{\code{data.frame} or \link[dplyr]{tibble} with columns for predicted and true values}

\item{observed}{Bare column name for the predicted value}

\item{truth}{Bare column name for the true value}

\item{positive}{Vector of length 1 specifying the value of the 'positive' class in the observed and truth columns; default is \code{1}}

\item{use_thresh}{Boolean indicating whether or not the accuracy measures calculated should be based on a threshold(s); this argument should only be set to \code{TRUE} if the 'observed' column is a vector of probabilities; if \code{TRUE} the 'thresh' argument will be used to capture thresholds to test; default is \code{FALSE} and the argument to 'thresh' is ignored}

\item{thresh}{Vector of thresholds to test; ignored if \code{use_thresh = FALSE}; default is \code{0.5}}
}
\value{
A \code{tibble} with at least one row and four columns: "threshold" (\code{NA} if \code{use_thresh = FALSE}), "precision", "recall", "f1". If \code{use_thresh = TRUE} the \code{tibble} returned will have as many rows as the length of the vector passed to "thresh".
}
\description{
Starting from a \code{tibble}, this function will calculate binary classification accuracy measures, including the precision and recall, as well as the F1 score, which is the harmonic mean of the two. The input data should include one column for the truth value, and another for the observed. The observed data can either be in the format of predicted outcome or a vector of probabilities. If probabilities are passed to the function, then the user may specify the threshold(s) to classify predicted outcome.
}
\details{
The following formulas are used to calculate the precision, recall, and F1 score:

\deqn{Precision =  TP/(TP+FP)}
\deqn{Recall =  TP/(TP+FN)}
\deqn{F1 =  2 x ((Precision x Recall) / (Precision + Recall))}

Note that F1 is the harmonic mean of precision and recall. The more general F beta score allows precision to be weighted greater than recall or vice versa.
}
\examples{

fit <- glm(am ~ mpg + wt, data = mtcars, family = "binomial")
resp <- predict(fit, newdata = dplyr::select(mtcars, wt, mpg), type = "response")
resp <- ifelse(resp > 0.5, 1, 0)
dat <- data.frame(am = mtcars$am, prediction = resp)

f1(dat, observed = prediction, truth = am, use_thresh = FALSE)


x <- rnorm(100, mean = 0.2, sd = 0.4)
y <- rnorm(100, mean = 0.6, sd = 0.4)
x <- bound(x)
y <- bound(y)
dat <- data.frame(probs = c(x,y), class = c(rep("x",100), rep("y", 100)))

f1(dat, observed = probs, truth = class, use_thresh = TRUE, thresh = c(0.4,0.5,0.6), positive = "x")

}
\references{
Sasaki, Yutaka. (2007). The truth of the F-measure. Teach Tutor Mater.
}
